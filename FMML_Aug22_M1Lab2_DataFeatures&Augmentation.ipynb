{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamyaKV134/FMML_COURSE_ASSIGNMENT/blob/main/FMML_Aug22_M1Lab2_DataFeatures%26Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FMML Module 1, Lab 2<br>\n",
        "Module Coordinator : amit.pandey@research.iiit.ac.in <br>"
      ],
      "metadata": {
        "id": "JN97BfHPX7yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The aim of this lab is to introduce DATA and FEATURES.\n",
        "We will study: Feature extraction and Data Augmentation.\n",
        "Let's get started.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q0DQhRGLo3Tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a copy before running the cells"
      ],
      "metadata": {
        "id": "o4AtXdwvNRGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data can be anything like text, image , sound signals, and even a mix of multiple types (multimodal). We need to learn how to handle raw data, and how to use them for our analysis."
      ],
      "metadata": {
        "id": "gkEBupTXa1xo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6I1yI79fbLD"
      },
      "source": [
        "# Extracting features from data\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimBnfcpvcNS"
      },
      "source": [
        "## Standard Imports.\n",
        "\n",
        "! pip install wikipedia\n",
        "\n",
        "import wikipedia\n",
        "import nltk\n",
        "from nltk.util import ngrams \n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import plotly.express as px\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are features? \n",
        "### Features are individual independent variables that act like an input to your system. \n",
        "A very basic example is: In z = x + y, x and y are the features.\n",
        "We can have simple features like above or even more complex features learned by our machine learning models (we will study these later on)."
      ],
      "metadata": {
        "id": "_f74mfnO8Rd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "\n",
        "from mpl_toolkits.mplot3d.axes3d import get_test_data\n",
        "\n",
        " \n",
        "# set up a figure twice as wide as it is tall\n",
        "fig = plt.figure(figsize=plt.figaspect(1))\n",
        "\n",
        "# =============\n",
        "# First subplot\n",
        "# =============\n",
        "# set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "\n",
        "# plot a 3D surface like in the example mplot3d/surface3d_demo\n",
        "X = np.arange(-5, 5, 0.25) # feature 1\n",
        "Y = np.arange(-5, 5, 0.25) # feature 2\n",
        "X, Y = np.meshgrid(X, Y)\n",
        "R = np.sqrt(X**2 + Y**2)\n",
        "Z = np.sin(R) #output\n",
        "surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
        "                       linewidth=0.4, antialiased=False)\n",
        "ax.set_zlim(-1.01, 1.01)\n",
        "fig.colorbar(surf, shrink=0.5, aspect=10)"
      ],
      "metadata": {
        "id": "n9KMUJBd8QKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6hGhIGiy4GP"
      },
      "source": [
        "# Part 2: Features of text\n",
        "How do we apply machine learning on text? We can't directly use the text as input to our algorithms. We need to convert them to features.They are converted into vectors (embeddings) or one hot encoded.  Let us explore a simple way of converting text to features. \n",
        "\n",
        "Let us download a few documents off Wikipedia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpUmCoEr2R3J"
      },
      "source": [
        "## set language and then download the data.\n",
        "\n",
        "topic1 = 'Giraffe'\n",
        "topic2 = 'Elephant'\n",
        "wikipedia.set_lang('en') \n",
        "eng1 = wikipedia.page(topic1).content\n",
        "eng2 = wikipedia.page(topic2).content\n",
        "wikipedia.set_lang('fr')\n",
        "fr1 = wikipedia.page(topic1).content\n",
        "fr2 = wikipedia.page(topic2).content\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7RlhMiO5kd"
      },
      "source": [
        "This is what the text looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW0G-t912UXZ"
      },
      "source": [
        "fr2 ## the french textual data describing the second topic."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZkmNJ7XO9xX"
      },
      "source": [
        "We need to clean this up a bit. Let us remove all the special characters and keep only 26 letters and space. Note that this will remove accented characters in French also. We are also removing all the numbers and spaces. So this is not an ideal solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5yf5P9pPI4t"
      },
      "source": [
        "def cleanup(text):\n",
        "  text = text.lower()  # make it lowercase\n",
        "  text = re.sub('[^a-z]+', '', text) # only keep characters, i.e. if not a-z then replace with space.\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = re.sub('[a-z]', '1', 'espèce d\\'« éléphant d\\?Afrique »,')\n",
        "text1"
      ],
      "metadata": {
        "id": "Iawqez-f4oT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrOjC32fRuTK"
      },
      "source": [
        "eng1 = cleanup(eng1)\n",
        "eng2 = cleanup(eng2)\n",
        "fr1 = cleanup(fr1)\n",
        "fr2 = cleanup(fr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIdqvL2G-LqL"
      },
      "source": [
        "print(eng1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of directly using characters as the features, to understand a text better, we may consider group of tokens i.e. ngrams as features.\n",
        " \n",
        "For this example let us consider that each character is one word, and let us see how n-grams work."
      ],
      "metadata": {
        "id": "XAJNs7PD_cVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## nltk library provides many tools for text processing, please explore them."
      ],
      "metadata": {
        "id": "E1pXE4sK_0kl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXFTWwd0rk63"
      },
      "source": [
        "Now let us calculate the frequency of the character n-grams. N-grams are groups of characters of size n. A unigram is a single character and a bigram is a group of two characters and so on. \n",
        "\n",
        "Let us count the frequency of each character in a text and plot it in a histogram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Lz3YUjN0L5"
      },
      "source": [
        "## Dont worry if you do not understand these functions right away, you can revisit them and follow step-by-step.\n",
        "\n",
        "# convert a tuple of characters to a string\n",
        "def tuple2string(tup):\n",
        "  st = ''\n",
        "  for ii in tup:\n",
        "    st = st + ii\n",
        "  return st\n",
        "\n",
        "# convert a tuple of tuples to a list of strings\n",
        "def key2string(keys):\n",
        "  return [tuple2string(i) for i in keys]\n",
        "\n",
        "# plot the histogram\n",
        "def plothistogram(ngram):\n",
        "  keys = key2string(ngram.keys()) \n",
        "  values = list(ngram.values())\n",
        "  \n",
        "  # sort the keys in alphabetic order\n",
        "  combined = zip(keys, values) ## keys i.e. characters on x axis and their count in the given doc as values.\n",
        "  zipped_sorted = sorted(combined, key=lambda x: x[0]) ## sorting based on keys, to get a to z order.\n",
        "  keys, values = map(list, zip(*zipped_sorted))\n",
        "  plt.bar(keys, values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHD62zbZcwAB"
      },
      "source": [
        "Let us compare the histograms of English pages and French pages. Can you spot a difference?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKcGRgH6b0KP"
      },
      "source": [
        "## we passed ngrams 'n' as 1 to get unigrams. Unigram is nothing but single token (in this case character).\n",
        "## ngrams imported from nltk, it returns ngrams from given string. Counter returns dictionary with keys as elements and counts as values.\n",
        "unigram_eng1 = Counter(ngrams(eng1,1)) ##just to get count of each element. \n",
        "plothistogram(unigram_eng1)\n",
        "plt.title('English 1')\n",
        "plt.show()\n",
        "unigram_eng2 = Counter(ngrams(eng2,1))\n",
        "plothistogram(unigram_eng2)\n",
        "plt.title('English 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDM_UhCL2QLt"
      },
      "source": [
        "unigram_fr1 = Counter(ngrams(fr1,1))\n",
        "plothistogram(unigram_eng1)\n",
        "plt.title('French 1')\n",
        "plt.show()\n",
        "unigram_fr2 = Counter(ngrams(fr2,1))\n",
        "plothistogram(unigram_fr2)\n",
        "plt.title('French 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A good feature is one that helps in easy prediction and classification. \n",
        "## for ex : if you wish to differentiate between grapes and apples, size can be one of the useful features."
      ],
      "metadata": {
        "id": "VUEys9KoA0L0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxgrdZLKdkAB"
      },
      "source": [
        "We can see that the unigrams for French and English are very similar. So this is not a good feature if we want to distinguish between English and French. Let us look at bigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmRCxItx2T9W"
      },
      "source": [
        "## Now instead of unigram, we will use bigrams as features, and see how useful bigrams are as features.\n",
        "\n",
        "bigram_eng1 = Counter(ngrams(eng1,2)) # bigrams\n",
        "plothistogram(bigram_eng1)\n",
        "plt.title('English 1')\n",
        "plt.show()\n",
        "\n",
        "bigram_eng2 = Counter(ngrams(eng2,2))\n",
        "plothistogram(bigram_eng2)\n",
        "plt.title('English 2')\n",
        "plt.show()\n",
        "\n",
        "bigram_fr1 = Counter(ngrams(fr1,2))\n",
        "plothistogram(bigram_eng1)\n",
        "plt.title('French 1')\n",
        "plt.show()\n",
        "\n",
        "bigram_fr2 = Counter(ngrams(fr2,2))\n",
        "plothistogram(bigram_fr2)\n",
        "plt.title('French 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-egsHMIg5Rp"
      },
      "source": [
        "Another way to visualize bigrams is to use a 2-dimensional graph."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## lets have a lot at bigrams.\n",
        "\n",
        "bigram_eng1\n"
      ],
      "metadata": {
        "id": "7LYSVe02dG59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EaPJgtaVxZM"
      },
      "source": [
        "## a function to plot 2-D histogram. The values are color mapped. \n",
        "\n",
        "def plotbihistogram(ngram):\n",
        "  freq = np.zeros((26,26))\n",
        "  for ii in range(26):\n",
        "    for jj in range(26):\n",
        "      freq[ii,jj] = ngram[(chr(ord('a')+ii), chr(ord('a')+jj))] #ord converts char to code\n",
        "  plt.imshow(freq, cmap = 'jet')\n",
        "  plt.colorbar()\n",
        "  return freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ord"
      ],
      "metadata": {
        "id": "4IFVtO8q8TJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7jq3AwnVzQT"
      },
      "source": [
        "bieng1 = plotbihistogram(bigram_eng1)\n",
        "plt.show()\n",
        "bieng2 = plotbihistogram(bigram_eng2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXPTOj67WsPT"
      },
      "source": [
        "bifr1 = plotbihistogram(bigram_fr1)\n",
        "plt.show()\n",
        "bifr2 = plotbihistogram(bigram_fr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGOEHcyGokD0"
      },
      "source": [
        "Let us look at the top 10 ngrams for each text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk2TkzTno8vb"
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "def ind2tup(ind):\n",
        "  ind = int(ind)\n",
        "  i = int(ind/26)\n",
        "  j = int(ind%26)\n",
        "  return (chr(ord('a')+i), chr(ord('a')+j))\n",
        "\n",
        "def ShowTopN(bifreq, n=10):\n",
        "  f = bifreq.flatten()\n",
        "  arg = np.argsort(-f)\n",
        "  for ii in range(n):\n",
        "    print(f'{ind2tup(arg[ii])} : {f[arg[ii]]}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HeWNh_q0QZ1"
      },
      "source": [
        "print('\\nEnglish 1:')\n",
        "ShowTopN(bieng1)\n",
        "print('\\nEnglish 2:')\n",
        "ShowTopN(bieng2)\n",
        "print('\\nFrench 1:')\n",
        "ShowTopN(bifr1)\n",
        "print('\\nFrench 2:')\n",
        "ShowTopN(bifr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## At times, we need to reduce the number of features. We will discuss this more in the upcoming sessions, but a small example has been discussed here. Instead of using each unique token (a word) as a feature, we reduced the number of features by using 1-gram and 2-gram of characters as features."
      ],
      "metadata": {
        "id": "RfwwQj_4CyBA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kDovOP4l98z"
      },
      "source": [
        "We observe that the bigrams are similar across different topics but different across languages. Thus, the bigram frequency is a good feature for distinguishing languages, but not for distinguishing topics. \n",
        "\n",
        "Thus, we were able to convert a many-dimensional input (the text) to 26 dimesions (unigrams) or 26*26 dimensions (bigrams).\n",
        "\n",
        "\n",
        "A few ways to explore:\n",
        "1. Try with different languages.\n",
        "2. The topics we used are quite similar, wikipedia articles of 'elephant' and 'giraffe'. What happens if we use very different topics? What if we use text from another source than Wikipedia?\n",
        "3. How can we use and visualize trigrams and higher n-grams?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "t1='Tiger'\n",
        "t2='Cow'\n",
        "t3='Parrot'\n",
        "wikipedia.set_lang('da') # for getting the data in Dansk\n",
        "x1 = wikipedia.page(t1).content #extracting the requried data from wikipedia\n",
        "x2 = wikipedia.page(t2).content\n",
        "x3=wikipedia.page(t3).content\n",
        "\n",
        "wikipedia.set_lang('af') #for getting the data in Afrikaans\n",
        "y1 = wikipedia.page(t1).content #extracting the requried data from wikipedia\n",
        "y2 = wikipedia.page(t2).content\n",
        "y3 = wikipedia.page(t3).content\n",
        "\n",
        "wikipedia.set_lang('eo') #for getting the datain Espranto\n",
        "z1 = wikipedia.page(t1).content #extracting the requried data from wikipedia\n",
        "z2 = wikipedia.page(t2).content\n",
        "z3 = wikipedia.page(t3).content\n",
        "\n"
      ],
      "metadata": {
        "id": "MQ7Q1Ui_tnu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 #for printing the text in "
      ],
      "metadata": {
        "id": "7SfsvVvwvkHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup(text):\n",
        "  text = text.lower()  # make it lowercase\n",
        "  text = re.sub('[^a-z]+', '', text) # only keep characters, i.e. if not a-z then replace with space.\n",
        "  return text"
      ],
      "metadata": {
        "id": "bYqIAsvHxjB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1=re.sub('[a-z]','1','https://da.wikipedia.org/wiki/Tiger')\n",
        "text2=re.sub('[a-z]','1','https://af.wikipedia.org/w/index.php?go=Go&search=Tiger&title=Spesiaal:Soek&ns0=1')\n",
        "text3=re.sub('[a-z]','1','https://eo.wikipedia.org/w/index.php?go=Go&search=tiger&title=Speciala%C4%B5o:Ser%C4%89i&ns0=1')"
      ],
      "metadata": {
        "id": "I0pM6bucxsAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1=cleanup(x1) #for cleaning up the characters other than alphabets\n",
        "x2=cleanup(x2)\n",
        "x3=cleanup(x3)\n",
        "y1=cleanup(x1)\n",
        "y2=cleanup(x2)\n",
        "y3=cleanup(x3)\n",
        "z1=cleanup(x1)\n",
        "z2=cleanup(x2)\n",
        "z3=cleanup(x3)\n",
        "\n"
      ],
      "metadata": {
        "id": "mKUiuqPY0j_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x1)"
      ],
      "metadata": {
        "id": "JW2e7Jlw05Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gx1=Counter(ngrams(x1,3)) #for obtaining a trigram \n",
        "plothistogram(gx1)\n",
        "plt.title(\"DANSK\") #for title\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aNhoG27v06uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gx1"
      ],
      "metadata": {
        "id": "92ttIOU57xG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gy1=Counter(ngrams(y1,3)) #for obtaining a trigram\n",
        "plothistogram(gy1)\n",
        "plt.title(\"AFRIKAANS\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e0UnwbiO6BlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gy1"
      ],
      "metadata": {
        "id": "XdFyd61N7tuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gz1=Counter(ngrams(z1,3)) #for obtaining a trigram\n",
        "plothistogram(gz1)\n",
        "plt.title(\"ESPRANTO\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QugJuW_V7dD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gz1"
      ],
      "metadata": {
        "id": "XgK1q-043SLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kXyJRmr8yTW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kA_ipbAHyPf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features of Images. \n",
        "### Images in digital format are stored as numeric values, and hence we can use these values as features. for ex : a black and white (binary) image is stored as an array of 0  and 255 or 0 and 1."
      ],
      "metadata": {
        "id": "CpA1eKZiDjTm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZJfjIHk-oHV"
      },
      "source": [
        "# Part 2: Written numbers\n",
        "\n",
        "We will use a subset of the MNIST dataset. Each input character is represented in a 28*28 array. Let us see if we can extract some simple features from these images which can help us distinguish between the digits.\n",
        "\n",
        "Load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNsLJSr6wGY0"
      },
      "source": [
        "from keras.datasets import mnist\n",
        " \n",
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVNr144WAUZO"
      },
      "source": [
        "Extract a subset of the data for our experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3MN8ddxAASZ"
      },
      "source": [
        "no1 = train_X[train_y==1,:,:] ## dataset corresponding to number = 1.\n",
        "no0 = train_X[train_y==0,:,:] ## dataset corresponding to number = 0."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePXCs0qyCLpc"
      },
      "source": [
        "Let us visualize a few images here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQeyZSh-Arpc"
      },
      "source": [
        "for ii in range(5):\n",
        "  plt.subplot(1, 5, ii+1)\n",
        "  plt.imshow(no1[ii,:,:])\n",
        "plt.show()\n",
        "for ii in range(5):\n",
        "  plt.subplot(1, 5, ii+1)\n",
        "  plt.imshow(no0[ii,:,:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = no1>0\n",
        "a.shape, no1.shape"
      ],
      "metadata": {
        "id": "n2UFfFWhCYzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to help you understand how the np.sum is working to find count of pixels that are not zero.\n",
        "\n",
        "mtx = np.arange(8).reshape(2,2,2)\n",
        "a = mtx>1\n",
        "a[0][0][0]\n",
        "type(a[0][0][0])\n"
      ],
      "metadata": {
        "id": "LHjttKNkDK29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We can even use value of each pixel as a feature. But let us see how to derive other features."
      ],
      "metadata": {
        "id": "2_1n_KXkE3zg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-Tg7EKDz96"
      },
      "source": [
        "Now, let us start with a simple feature: the sum of all pixels and see how good this feature is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8SztDk7CyZc"
      },
      "source": [
        "## sum of pixel values.\n",
        "\n",
        "sum1 = np.sum(no1>0, (1,2)) # threshold before adding up\n",
        "sum0 = np.sum(no0>0, (1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oW3XCOCE7Zv"
      },
      "source": [
        "Let us visualize how good this feature is: (X-axis is mean, y-axis is the digit)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum1.shape"
      ],
      "metadata": {
        "id": "LDz2vOp_GAZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8PIe8o_DPpU"
      },
      "source": [
        "plt.hist(sum1, alpha=0.7);\n",
        "plt.hist(sum0, alpha=0.7);\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hToEepFtl2"
      },
      "source": [
        "We can already see that this feature separates the two classes quite well.\n",
        "\n",
        "Let us look at another, more complicated feature. We will count the number black pixels that are surrounded on four sides by non-black pixels, or \"hole pixels\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwEnlm6RFFej"
      },
      "source": [
        "def cumArray(img):\n",
        "  img2 = img.copy()\n",
        "  for ii in range(1, img2.shape[1]):\n",
        "    img2[ii,:] = img2[ii,:] + img2[ii-1,:]  # for every row, add up all the rows above it.\n",
        "  #print(img2)\n",
        "  img2 = img2>0\n",
        "  #print(img2)\n",
        "  return img2\n",
        "\n",
        "def getHolePixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  hole = hull & ~ (img>0) # remove the original digit to leave behind the holes\n",
        "  return hole\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw3HjgnupUEI"
      },
      "source": [
        "Visualize a few:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0sjr23NYEFe"
      },
      "source": [
        "imgs = [no1[456,:,:],  no0[456,:,:]]\n",
        "for img in imgs:\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(getHolePixels(img))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS-4erNXtxMi"
      },
      "source": [
        "Now let us plot the number of hole pixels and see how this feature behaves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpm1dRgsety8"
      },
      "source": [
        "hole1 = np.array([getHolePixels(i).sum() for i in no1])\n",
        "hole0 = np.array([getHolePixels(i).sum() for i in no0])\n",
        "  \n",
        "plt.hist(hole1, alpha=0.7);\n",
        "plt.hist(hole0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjCBHpJ31yq"
      },
      "source": [
        "This feature works even better to distinguish between one and zero. \n",
        "\n",
        "\n",
        "Now let us try the number of pixels in the 'hull' or the number with the holes filled in:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzH26ElXNri"
      },
      "source": [
        "Let us try one more feature, where we look at the number of boundary pixels in each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-2czBypXMwT"
      },
      "source": [
        "def minus(a, b):\n",
        "  return a & ~ b\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "  img = img.copy()>0  # binarize the image\n",
        "  rshift = np.roll(img, 1, 1)\n",
        "  lshift = np.roll(img, -1 ,1)\n",
        "  ushift = np.roll(img, -1, 0)\n",
        "  dshift = np.roll(img, 1, 0)\n",
        "  boundary = minus(img, rshift) | minus(img, lshift) | minus(img, ushift) | minus(img, dshift)\n",
        "  return boundary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-V688jFerXh"
      },
      "source": [
        "imgs = [no1[456,:,:],  no0[456,:,:]]\n",
        "for img in imgs:\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(getBoundaryPixels(img))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSsxsbCNXcNh"
      },
      "source": [
        "bound1 = np.array([getBoundaryPixels(i).sum() for i in no1])\n",
        "bound0= np.array([getBoundaryPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(bound1, alpha=0.7);\n",
        "plt.hist(bound0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuP04Ao_R0Yz"
      },
      "source": [
        "What will happen if we plot two features together? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDGHlFSd5Fu"
      },
      "source": [
        "Feel free to explore the above graph with your mouse. \n",
        "\n",
        "\n",
        "We have seen that we extracted four features from a 28*28 dimensional image.\n",
        "\n",
        "\n",
        "Some questions to explore:\n",
        "1. Which is the best combination of features?\n",
        "2. How would you test or visualize four or more features?\n",
        "3. Can you come up with your own features?\n",
        "4. Will these features work for different classes other than 0 and 1?\n",
        "5. What will happen if we take more that two classes at a time?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1A. The combination of Independent Component Analysis (ICA) and Principal Component Analysis(PCA) is the best for feature extraction. \n",
        "\n",
        "2A. The features which we extract from the data must be simple so that it becomes easy for us to compare with other features.\n",
        "\n",
        "3A.\n",
        "**Profiles :** It counts the number of pixels between the bounding  box of the character image and the edge of the character.\n",
        "**Direction Features :** We distinguish the line segments based onthe skeleton of the character image. We also label the line segment information.\n",
        "\n",
        "4A. These features will definitely work for digits other than 1 or 0 as the direction of each digit vary from other similarly the number of pixels between bounding box also differ. So, we can use them .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2nIPCzA7Pjw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9_3sYvQAKkRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features from CSV file"
      ],
      "metadata": {
        "id": "gIJdT3tYIMyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/california_housing_train.csv')"
      ],
      "metadata": {
        "id": "SfR0jKjRI9fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "9VU02WsOJLs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "XCeIl4kMJc59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})\n"
      ],
      "metadata": {
        "id": "foQSY_tvJOua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "sns.set(style = \"darkgrid\")\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection = '3d')\n",
        "\n",
        "x = df['total_bedrooms'][:50]\n",
        "y = df['housing_median_age'][:50]\n",
        "z = df['median_house_value'][:50]\n",
        "\n",
        "ax.set_xlabel(\"total_bedrooms\")\n",
        "ax.set_ylabel(\"housing_median_age\")\n",
        "ax.set_zlabel(\"median_house_value\")\n",
        "\n",
        "ax.scatter(x, y, z)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LaSdj2-HItaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Task :\n",
        "## Download a CSV file from the internet, upload it to your google drive.\n",
        "## Read the CSV file and plot graphs using different combination of features and write your analysis\n",
        "## Ex : IRIS flower datasaet"
      ],
      "metadata": {
        "id": "vGGbRUz3J8Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "r=pd.read_csv('/content/consumers-price-index-june-quarter-2022-index-numbers.csv')"
      ],
      "metadata": {
        "id": "25EnrFLPk_zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.head()"
      ],
      "metadata": {
        "id": "HGjplEhGlOCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.columns"
      ],
      "metadata": {
        "id": "wT4TCTiHlMIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r=r.rename(columns={'sr':'p','sr1':'p1'})"
      ],
      "metadata": {
        "id": "By_uikEblUBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "metadata": {
        "id": "uQp1ORmElaXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "f=plt.figure()\n",
        "ax=f.add_subplot(111,projection=\"3d\")\n",
        "x = r ['Period'][:50]\n",
        "y = r ['Data_value'][:50]\n",
        "ax.set_xlabel(\"year\")\n",
        "ax.set_ylabel(\"data_value\")\n",
        "ax.scatter(x,y)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "ykkV5XDElsy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above graph shows the consumers price in the month of June in 2022.\n",
        "\n",
        "Here we consider 2 columns as the main ones which are data_values and periods\n",
        "\n",
        "1.On X-axis we take years(periods)\n",
        "\n",
        "2.On Y-axis we take data_values\n",
        "\n",
        "3.On Z-axis we take the values\n",
        "\n",
        "Here, I downloaded a CSV file from the chrome and uploaded in google drive and then I extracted the data by copying the path using pandas and plotted the graph.\n",
        "\n",
        "By this analysis, we can easily understand how the consumer prices changed in June 2022. And from that we can do further predictions"
      ],
      "metadata": {
        "id": "ni1ud8FhbFnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation\n",
        "It is a technique to increase the diversity of our training set by applying random (but realistic) transformations, such as image rotation, change of color etc. When we have limited training data, we can augment our data with help of these techniques."
      ],
      "metadata": {
        "id": "UEjCCSQh1d7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "# set randomseed\n",
        "rng = np.random.default_rng(seed=42)\n",
        "from sklearn.utils.extmath import cartesian\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "import math"
      ],
      "metadata": {
        "id": "XePcTeKI1dGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this lab we will use a subset of MNIST that is very small, to better understand the effect of augmentation."
      ],
      "metadata": {
        "id": "ZP0Z3oOT2Vqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "print(\"original data size:\",train_X.shape)\n"
      ],
      "metadata": {
        "id": "7miTQ_032Rxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[0].shape,train_y[0])"
      ],
      "metadata": {
        "id": "79iYoK4a2Y8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_X[0])"
      ],
      "metadata": {
        "id": "F-ne2Jrl6R3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X[::1200,:,:].copy() # subsample. Otherwise it will take too long!\n",
        "train_y = train_y[::1200].copy() # do the same to the labels\n",
        "\n",
        "print(\"Now it is:\", train_X.shape)"
      ],
      "metadata": {
        "id": "g3YMYR2L6VqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation 1: rotation\n",
        "Let us try rotating the image a little. We will use skimage library for this."
      ],
      "metadata": {
        "id": "JgN85vRl6847"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_X[2], cmap='gray')\n",
        "plt.show()\n",
        "print(train_X[2].shape)\n",
        "plt.imshow(rotate(train_X[2],45), cmap='gray')"
      ],
      "metadata": {
        "id": "jStJv7xG6cNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After rotating, the the class of the image is still the same. Let us make a function to rotate multiple images by random angles. We want a slightly different image every time we run this function. So, we generate a random number between 0 and 1 and change it so that it lies between -constraint/2 and +constraint/2"
      ],
      "metadata": {
        "id": "phr4sXEb94Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augRotate(sample, angleconstraint):\n",
        "  if angleconstraint==0:\n",
        "    return sample\n",
        "\n",
        "  print(\"shape of sample before is:\", sample.shape)\n",
        "  print(\"len(sample.shape)\", len(sample.shape))\n",
        "  if len(sample.shape)==2:\n",
        "    sample = np.expand_dims(sample, 0)  # make sure the sample is 3 dimensional\n",
        "    print(\"shape of sample is:\", sample.shape)\n",
        "  angle = rng.random(len(sample)) # generate random numbers for angles\n",
        "  print(\"angle is:\", angle)\n",
        "  angle = (angle-0.5)*angleconstraint # make the random angle constrained\n",
        "  print(\"angle with constraint is:\", angle)\n",
        "  nsample = sample.copy() # preallocate the augmented array to make it faster\n",
        "  for ii in range(len(sample)):\n",
        "    nsample[ii] = rotate(sample[ii], angle[ii])\n",
        "  return np.squeeze(nsample) # take care if the input had only one sample."
      ],
      "metadata": {
        "id": "B3ai_7aN7Csn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function returns a slightly different image each time we call it. So we can increase the number of images in the sample by any multiple. "
      ],
      "metadata": {
        "id": "udOWwYj2-Bsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_X[20]\n",
        "angleconstraint = 70\n",
        "# show the original image\n",
        "plt.imshow(sample, cmap='gray')\n",
        "plt.show()\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # show an augmented image\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # show another augmented image from the same sample\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # one more image from the same sample"
      ],
      "metadata": {
        "id": "vyO8Ap9-98LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us try one more augmentation, Shear: A transformation in which all points along a given line remain fixed while other points are shifted parallel to by a \n",
        " distance proportional to their perpendicular distance from. Shearing a plane figure does not change its area. "
      ],
      "metadata": {
        "id": "siEhyuX0AyZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shear(sample, amount):\n",
        "  tform = AffineTransform(shear = amount) # create the shear transform\n",
        "  img = warp(sample, tform) # apply the shear\n",
        "  # this makes the digit off-center. Since all the images in the test set are centralized, we will do the same here\n",
        "  col = img.sum(0).nonzero()[0]\n",
        "  row = img.sum(1).nonzero()[0]\n",
        "  if len(col)>0 and len(row)>0:\n",
        "    xshift = int(sample.shape[0]/2 - (row[0]+row[-1])/2)\n",
        "    yshift = int(sample.shape[1]/2 - (col[0]+col[-1])/2)\n",
        "    img = np.roll(img, (xshift, yshift),(0,1))\n",
        "  return img"
      ],
      "metadata": {
        "id": "46nKQ_Qj-Elg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_X[2]\n",
        "plt.imshow(sample, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# apply shear\n",
        "plt.imshow(shear(sample, 0.4), cmap='gray')"
      ],
      "metadata": {
        "id": "Zae7PZcUBDt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let us also see skeletonization of image"
      ],
      "metadata": {
        "id": "4NglWyeSDtxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.morphology import skeletonize\n"
      ],
      "metadata": {
        "id": "XQMsvuD5BITy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skeleton = skeletonize(train_X[2],method='lee')\n",
        "plt.imshow(skeleton, cmap='gray')"
      ],
      "metadata": {
        "id": "ze1kf_0BD0YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Structuring elements that are repeatedly used for thinning\n",
        "\n",
        "S1 = np.array([[0,0,0],[-1,1,-1],[1,1,1]]) # -1 for dont care\n",
        "S2 = np.array([[-1,0,0],[1,1,0],[-1,1,-1]])\n",
        "\n",
        "\n",
        "def CheckMatch(window,kernel):\n",
        "  for i in range(window.shape[0]):\n",
        "        for j in range(window.shape[1]):\n",
        "            if kernel[i,j]!=-1 and window[i,j]!=kernel[i,j]:\n",
        "                return False\n",
        "  return True\n",
        "\n",
        "def ApplyKernel(image,kernel): #used\n",
        "  height, width =  image.shape\n",
        "  res = np.copy(image)\n",
        "  for i in range(1,height-1):\n",
        "    for j in range (1,width-1):\n",
        "      window = image[i-1:i+2,j-1:j+2]\n",
        "      #print('window shape',window.shape)\n",
        "      Match_result = CheckMatch(window,kernel)\n",
        "      if (Match_result):\n",
        "        res[i,j]=0\n",
        "  return res\n",
        "\n",
        "\n",
        "\n",
        "def Skeletonization(image):\n",
        "  '''pass binary image'''\n",
        "  #new = np.copy(image)\n",
        "  #old = np.zeros(image.shape,dtype=np.uint8)\n",
        "  count = 1\n",
        "  change = 1000\n",
        "  while (change >0.01):\n",
        "    print('count',count)\n",
        "    new = image\n",
        "    new = ApplyKernel(new,S1)\n",
        "    new = ApplyKernel(new,S2)\n",
        "    new = ApplyKernel(new,np.rot90(S1,1)) #90 degree rotate\n",
        "    new = ApplyKernel(new,np.rot90(S2,1))\n",
        "    new = ApplyKernel(new,np.rot90(S1,2)) # 180 degree rotate\n",
        "    new = ApplyKernel(new,np.rot90(S2,2))\n",
        "    new = ApplyKernel(new,np.rot90(S1,3)) # 270 degree rotate\n",
        "    new = ApplyKernel(new,np.rot90(S2,3))\n",
        "    count+= 1\n",
        "    change = np.mean(np.abs(new-image))\n",
        "    image = new\n",
        "    plt.imshow(new,cmap='gray')\n",
        "    plt.show()\n",
        "  return new"
      ],
      "metadata": {
        "id": "ewpZG5b-D9F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binarized  =( train_X[0] > 0 ).astype(np.uint8)"
      ],
      "metadata": {
        "id": "LwgK5XObNcjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skeleton_five = Skeletonization(binarized)"
      ],
      "metadata": {
        "id": "oyQrnHghLADQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}